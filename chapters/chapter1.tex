%!TEX root = ../dissertation.tex
\begin{savequote}[75mm]
Nulla facilisi. In vel sem. Morbi id urna in diam dignissim feugiat. Proin molestie tortor eu velit. Aliquam erat volutpat. Nullam ultrices, diam tempus vulputate egestas, eros pede varius leo.
\qauthor{Quoteauthor Lastname}
\end{savequote}

\chapter{Background and Related Work}
\label{ch:background}

%\newthought{There's something to be said} for having a good opening line.

\section{Previous Work by Genter and Stone}
Our work strongly builds upon the work of Genter and Stone, who have recently
published a series of papers on the best way to influence an existing flock to
change direction \cite{genter2015placement, genter2014neighborsorientherd,
genter2013visionstationary, genter2013backsearch,
genter2016facegoalfacecurrent, genter201612steplookahead}.
This prior literature has studied a number of placement strategies and
influencing agent behaviors, including questions of how best to join or leave
a flock in real scenarios.
Genter's PhD thesis also presents results from simulations with a slightly
different implementation of Reynold's flocking model, as well as physical
experiments with these algorithms in a small RoboCup setting.

This work has studied influencing agents in a number of contexts, including
convergence in a small setting and steering a small, dense flock around an
obstacle.
We are primarily interested in building upon the work from the former context,
although the second context is still interesting.
In their experiments, Genter and Stone place $180$ flocking agents and $20$
influencing agents on a $150\times150$ toroidal grid, and let agents influence
each other if they are in a neighborhood radius of $20$ units or less from each
other.
As a result, they simulate the dynamics of an extremely high-density flock.
In our work, we introduce new settings to study dynamics in low-density flocks.
We will introduce the formal flocking model and discuss Genter and Stone's
placement strategies and algorithms in more detail in \S\ref{ch:problem} and
\S\ref{ch:influencing}, but we will summarize Genter and Stone's key results
here to help situate our results.

Genter and Stone introduce a number of behaviors for influencing agents and
compare them against two baselines: \textit{face} and \textit{offset momentum}.
In \textit{face}, influencing agents simply face a predetermined goal direction
at all times; in \textit{offset momentum}, influencing agents look at their
neighbors, calculate an average velocity vector, and choose a direction to
offset that velocity from the predetermined goal direction.
The most promising behavior they study is \textit{one step lookahead}; in this
behavior, influencing agents cycle through choices for every direction they
can take, and simulate one step of their neighbors for every choice they take.
The agents pick the choice that minimizes the average difference of their
neighbors from the goal direction.
Not surprisingly, \textit{one step lookahead} beats the baseline behaviors in
their experiments.
We will see that this is not the case in low-density settings and discuss the
reasons behind this surprising shift in \S\ref{ch:results}.

\section{Other Related Work in Flocking}
There is a rich history of work studying flocking, much of it concentrating on
flocking models originally proposed by Reynolds \cite{reynoldsmodel} and,
independently, Vicsek \cite{vicsek1995}.
The classical Reynolds model identifies three properties necessary for
flocking:
\begin{itemize}
    \item Alignment: a tendency for flocking agents to steer towards the
            average heading of their neighbors
    \item Avoidance: a tendency for flocking agents to avoid collisions with
            their neighbors
    \item Cohesion: a tendency for flocking agents to steer towards the average
            position of their neighbors
\end{itemize}
\noindent Separately, Vicsek proposed a flocking model mathematically
equivalent to the alignment portion of the Reynolds model.
As a result, many subsequent studies that build off the Reynolds or Vicsek
models, including the studies of Genter and Stone, only study the alignment
portion.

TALK ABOUT REYNOLDS, VISCEK MODEL

THEN TALK ABOUT INFLUENCING AGENTS: COUZIN, IN MORE DETAIL

THEN ALL THE OTHER INFLUENCING AGENT STRATEGIES

\section{Genetic Programming}
\label{sec:relatedgenetic}
REWRITE THIS SECTION IN MY VOICE

We are also not the first researchers to apply genetic algorithms to the domain
of controlling agents in swarms; Dorigo and Trianni used genetic algorithms to
evolve controllers for s-bots, swarming robots designed to self-assemble and
move together as a swarm-bot \cite{DorigoSwarmBot}.
However the problem solved in that research is not the same as the problem we
attempt to solve.
In the swarm-bot project, the evolved controllers ran cooperatively on every
agent in the swarm, whereas our controllers only run on a minority of the
agents yet still need to influence the collective behavior of the swarm.
Another key difference is that Dorigo and Trianni used a neural network
connecting the sensors to the actuators of their robots as their genome,
whereas we draw on the genetic programming literature to evolve controlling
programs that are able to handle varying amounts of input data and display
arbitrarily complex behaviors.

Another use of genetic algorithms for developing controllers was when Sean Luke
used genetic programming to build a team for the RoboCup97 competition
\cite{lukeRoboCup97}.
Like us, Luke used genetic programming with a domain specific language designed
based on domain intuition, however his language had many more primitives than
ours because the virtual soccer players he was evolving were capable of much
more complex behaviors than our flocking agents.
The execution model used by the RoboCup players was designed to simplify the
work to be done by the evolved program without unnecessarily biasing it toward
any particular strategy.
We have similar goals when designing our own execution model and language.

Much work has been done on developing techniques for evolving programs in
richer languages with complex constraints on which programs are valid
\cite{BriggsGP}.
Although we use functional programming ideas in our execution model, we keep
our language simple, with only conditional expressions for control flow
structures and only a single type.
Exploring a richer language with a type system to reduce the number of useless
programs our genetic algorithm searches would be very interesting, but we leave
it as future work.

\section{Barbara Related Work}
Our work builds mainly upon the work of Genter and Stone, who have recently
published a series of papers on the best way to influence an existing flock to
change direction \cite{genter2015placement, genter2014neighborsorientherd,
genter2013visionstationary, genter2013backsearch,
genter2016facegoalfacecurrent, genter201612steplookahead}.
This prior literature has studied a number of placement strategies and
influencing agent behaviors, including questions of how best to join or leave a
flock in real scenarios.
Genter's PhD thesis also presents results from simulations with a slightly
different implementation of Reynold's flocking model, as well as physical
experiments with these algorithms in a small RoboCup setting.
This prior literature has almost exclusively studied small environments, where
density of agents is high, and quick flock formation is virtually guaranteed.
In our work, we study two new low-density environments and introduce new
placement strategies and influencing agent behaviors to adapt to the
difficulties presented by these new environments.

Han et. al. have \cite{han2010teleporting} published a series of papers showing
how to align a group of agents in the same direction.
This literature has assumed a single influencing agent with infinite speed, and
has used this property to construct a behavior that has the influencing agent
fly around and correct the orientation of agents one at a time.
The result is that the Reynolds-Viscek agents all eventually converge to the
target direction, but are not connected to each other.
In our work, we limit the speed of influencing agents to be the same as the
Reynolds-Viscek agents to prevent the use of behaviors like this, and in hopes
that our results will be more applicable to real applications; we suspect that
influencing agents that act similarly to real birds will be more successful in
real-world applications.

Jadbadbaie et. al. \cite{jad2003convergence} have studied variations on the
Reynolds flocking model from an analytical perspective, with no influencing
agents.
A strong result from this literature is that a group of Reynolds-Viscek agents
in a toroidal setting will eventually converge regardless of initial
conditions.
However, there has been less analytical work on the speed of flock formation,
and very little on the use of influencing agents to speed up flock formation or
to force flocks to face given directions.

Su. et. al. \cite{su2009virtualleaderinformed} have also studied the question
of flock formation and convergence, but have studied the question in the
context of the Olfati-Saber flocking model
\cite{olfati2006virtualleaderinformed}.
This model assumes the existence of a single virtual leader that
non-influencing agents know about.
The virtual leader plays the role of an influencer here, but has special
control over the other agents based on its status.
In our work, we assume that influencing agents do not have any special
interaction rules with Reynolds-Viscek agents.

Couzin et. al. \cite{couzin2005} have studied this question with a slightly
different formulation, and with a different model of flocking behavior.
In their model, flocking behavior is achieved by maintaining distance between
neighbors, and they cast the problem as one of informed individuals (analogous
to influencing agents) trying to change the trajectory of the flock.
The informed individuals are not externally-controlled; they simply have
information about the ``correct" orientation.
In particular, the informed individuals can be wrong or have different opinions
than other individuals, so information transfer is key.
This differs from the settings we study, where influencing agents are
completely autonomous and agree on a goal direction.

Other researchers have tackled this question with real flocking agents.
Halloy et. al. \cite{Halloy2007} have used robotic influencing agents to move
cockroaches to areas they would otherwise avoid.
Cockroaches display flocking behavior, but with very different models from the
one that we study.
In this case, Halloy et. al. have exploited the cockroaches' inability to
differentiate between real cockroaches and the robotic influencing agents.

Vaughan et. al. \cite{vaughan98} have used robotic influencing agents to herd
a flock of ducks (on the ground) to a goal position in a small caged area.
The approach here largely uses the robot agents to ``push" the ducks from a
distance, like a dog herding sheep.
The dynamics in this case are very different from the models we study; when the
ducks are on the ground, they can stand still, for instance, and the fence
limits the ducks' behavior.

\section{Radhika Related Work}
\subsection{Flocking}
\label{sec:relatedflocking}
Our work builds mainly upon the work of Genter and Stone, who have recently
published a series of papers on the best way to influence an existing flock to
change direction \cite{genter2015placement, genter2014neighborsorientherd,
genter2013visionstationary, genter2013backsearch,
genter2016facegoalfacecurrent, genter201612steplookahead}.
This prior literature has studied a number of placement strategies and influencing
agent behaviors, including questions of how best to join or leave a flock in real
scenarios.
Genter's PhD thesis also presents results from simulations with a slightly
different implementation of Reynold's flocking model, as well as physical
experiments with these algorithms in a small RoboCup setting.
This prior literature has exclusively studied hand-constructed placement
strategies and behaviors.
In our work, we present first steps towards automating the design process by
evolving local components of influencing agent behaviors.

We also draw from previous work that studied Genter and Stone's algorithms in
low-density settings and proposed new algorithms to deal with the issues
introduced by low-density settings \cite{Fu2017}.
This previous work showed that, in low-density settings, maintaining influence
was of paramount importance.
In our work, we draw from the settings and behaviors presented in the previous
work to conduct a full analysis of our genetic behaviors.

Han et. al. have \cite{han2010teleporting} published a series of papers showing how
to align a group of agents in the same direction.
This literature has assumed a single influencing agent with infinite speed, and
has used this property to construct a behavior that has the influencing agent
fly around and correct the orientation of agents one at a time.
The result is that the Reynolds-Viscek agents all eventually converge to the target
direction, but are not connected to each other.
In our work, we limit the speed of influencing agents to be the same as the
Reynolds-Viscek agents to prevent the use of behaviors like this, and in hopes
that our results will be more applicable to real applications; we suspect that
influencing agents that act similarly to real birds will be more successful in
real-world applications.
Furthermore, we limit our genetic behaviors to only consider stimuli in an
influencing agent's neighborhood.
However, we are hopeful that, with more work, genetic programming techniques
can help develop behaviors for models that work under different situations and
assumptions.

Jadbadbaie et. al. \cite{jad2003convergence} have studied variations on the
Reynolds flocking model from an analytical perspective, with no influencing agents.
A strong result from this literature is that a group of Reynolds-Viscek agents in
a toroidal setting will eventually converge regardless of initial conditions.
However, there has been less analytical work on the speed of flock formation, and
very little on the use of influencing agents to speed up flock formation or to
force flocks to face given directions.

Su. et. al. \cite{su2009virtualleaderinformed} have also studied the question of
flock formation and convergence, but have studied the question in the context of
the Olfati-Saber flocking model \cite{olfati2006virtualleaderinformed}.
This model assumes the existence of a single virtual leader that non-influencing
agents know about.
The virtual leader plays the role of an influencer here, but has special control
over the other agents based on its status.
In our work, we assume that influencing agents do not have any special
interaction rules with Reynolds-Viscek agents.

Couzin et. al. \cite{couzin2005} have studied this question with a slightly
different
formulation, and with a different model of flocking behavior.
In their model, flocking behavior is achieved by maintaining distance between
neighbors, and they cast the problem as one of informed individuals (analogous to
influencing agents) trying to change the trajectory of the flock.
The informed individuals are not externally-controlled; they simply have
information about the ``correct" orientation.
In particular, the informed individuals can be wrong or have different opinions
than other individuals, so information transfer is key.
This differs from the settings we study, where influencing agents are completely
autonomous and agree on a goal direction.

Other researchers have tackled this question with real flocking agents.
Halloy et. al. \cite{Halloy2007} have used robotic influencing agents to move
cockroaches to areas they would otherwise avoid.
Cockroaches display flocking behavior, but with very different models from the
one that we study.
In this case, Halloy et. al. have exploited the cockroaches' inability to
differentiate between real cockroaches and the robotic influencing agents.

Vaughan et. al. \cite{vaughan98} have used robotic influencing agents to herd
a flock of ducks (on the ground) to a goal position in a small caged area.
The approach here largely uses the robot agents to ``push" the ducks from a
distance, like a dog herding sheep.
The dynamics in this case are very different from the models we study; when the
ducks are on the ground, they can stand still, for instance, and the fence
limits the ducks' behavior.

