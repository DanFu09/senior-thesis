%!TEX root = ../dissertation.tex
\chapter{Introduction}
\label{ch:introduction}

%\section{Format}
%FORMAT:
%
%Introduce flocking, then introduce influencing agents. Talk about low-density
%vs. high-density, and briefly mention hand-crafted algorithms for dealing with
%low-density flocking. Finally, talk about using genetic algorithms for both.

%\section{Barbara Intro}

Across nature, flocking behavior can be found in a variety of species, from 
flocks of birds, to herds of quadrupeds, schools of fish, or swarms of insects.
In such species, groups exhibiting collective behavior emerge from simple, 
local rules \citep{sumpter2010collective}.
An open question is whether externally-controlled influencing agents can be 
used to affect the behavior of flocks.

Previous work \cite{genter2013backsearch, genter2013visionstationary, 
genter2014neighborsorientherd, genter2015placement, genter2016facegoalfacecurrent, 
genter201612steplookahead, genterthesis}
has explored the use of influencing agents to guide flocking 
agents to face a target direction in small and toroidal settings.
In such settings, agent density is high, so interactions are common, and flock
formation is rapid.
In this work, we build upon past work by studying lower-density settings where
interactions are rarer and flock formation is more difficult.
As a result, influencing agent priorities must change in these settings to be
successful.
We tackle the problems introduced by these new settings by introducing new
influencing agent strategies and by using genetic programming to automatically
explore a wide range of the solution space.

Low-density settings are important to study because they capture dynamics in
situations where flocking may not occur naturally, but where we might want to
instigate flocking behavior; imagine a herd of buffalo that is currently
grazing, or a spooked flock of birds where individual agents fail to
coordinate.
It may also have implications for coordination in low-density swarms of
robotic multi-agent systems, where control may be imperfect, such as RoboBees
\cite{Chen2017Robobees}.
More broadly, flocking has implications for consensus in animal groups
\cite{Yang2006Consensus, sumpter2008fish, couzin2005} and in human social
networks \cite{liang2012opinion};
it has also been used to model multivariate timeseries and study human
movement \cite{schruben2010multivariate, singham2011agentmovement}.
In all these cases, agent density may vary greatly, so it is important to
understand influencing agent dynamics in both low density and high density
settings.

% Flock formation has implications for physical systems of birds, but also has
% many broader applications.
% For example, this question can be rephrased as one of finding consensus on a
% social network with dynamic topology and apply it to consensus among a group
% of people, or recast it as a question of preventing traffic jams in a group
% of human-driven cars, given a few self-driving cars (where the self-driving
% cars are the ``influencing agents").\cite{selfdrivingcars}
% The opposite question of making flocks robust to external influencing agents
% could have implications for broader political discourse (preventing the
% dissemination of fake news, for example).

For our work, we draw heavily from a recent series of studies of this problem by
Genter and Stone \cite{genter2013backsearch, genter2013visionstationary, 
genter2014neighborsorientherd, genter2015placement, genter2016facegoalfacecurrent, 
genter201612steplookahead, genterthesis}.
Genter and Stone study influencing agent placement and behavior in small,
toroidal environments.\footnote{In a toroidal environment, agents that exit the
simulation space from one side immediately re-appear on the other side}
In such environments, agents are bound to a small space and have unlimited 
opportunities to re-enter the screen and join a flock; flock formation is rapid.

We study this question in a more adverse environment by proposing two new test 
settings with lower agent density.
In one setting, we keep the simulation space toroidal but increase the size of
the space by several factors, greatly decreasing agent density.
Flock formation is still provably guaranteed in this setting, but is much less
rapid, so we study whether influencing agents can speed up flock formation.
In the other setting, we make the simulation space non-toroidal but start the
flocking agents in a circle in the center.
Since this space is non-toroidal, flock formation is not guaranteed, so we
study whether influencing agents can instigate flocking behavior by keeping the
flocking agents in a pre-defined area, or move them all in a certain direction.

%To help organize our analysis, we consider three different aspects of
%influencing agent design: placement strategy, local behaviors, and global
%behaviors.
%Placement strategies refer to the initial placement of influencing agents in the
%simulation space and their placement relative to flocking agents.
%Local behaviors dictate how an influencing agent attempts to influence local
%neighbors to face a given goal direction.
%Global behaviors, on the other hand, dictate how influencing agents determine
%their goal direction.
%For example, we might program all the influencing agents to have a
%pre-determined goal direction such as East or South, or we might program a
%global behavior that picks a goal direction after some time based on the
%initial dynamics of the simulation.

We find that in environments with low agent density, agent interactions are rare,
so results from experiments in smaller settings do not translate well to larger
settings.
In particular, when agent interactions are rare, maintaining a connection to
the flock becomes a key factor in the efficacy of influencing agent behaviors.
As a result, simple local behaviors such as ``face the goal direction" are
often superior to more complex local behaviors that try to optimize for speed.
We also experiment with a number of new behaviors and find that a multi-stage 
approach of ``follow-then-influence" can be effective in certain 
situations.
In this approach, influencing agents start out by obeying the flocking rules,
embedding themselves inside small, naturally-forming flocks.
After some time, the influencing agents start influencing their neighbors to
face a given goal direction.
Finally, we find that reasonable placement strategies are often 
interchangeable, and that more complex strategies often perform similarly to 
random strategies.

Next, we use genetic programming to generate different new behaviors.
In order to build behaviors that work with variable numbers of neighbors, we
evolve programs that are applied iteratively to each neighbor using
a functional programming construct called a fold.
In a fold, a function is applied in turn to each item in a list, updating an
accumulator value for each one.
The final value of the computation is the value of the accumulator after each
item has been folded over.

We define a simple language that performs arithmetic computations
on scalar values and angles, and evolve different functions to use in the fold.
To make the evolutionary process fast enough, we first evaluate different
functions in a small environment, with six neighbors that start in a circle
around a single influencing agent.
We run four trials; in each trial, the six neighbors (and the influencing agent)
are facing one of the cardinal directions, and the target direction is east.
We measure the average angle offset from the goal direction of the flocking
agents after $100$ steps and take the average across the four trials as the
fitness value for the proposed program.
We then run the evolutionary algorithm on this fitness value and mutate the
best candidates each generation.

To evaluate these behaviors in a wider context, we then test them in our two
new settings as well.
We find that the genetic behaviors can both encourage faster convergence in the
short term while still maintaining influence over the long-term.
As a result, they can perform as well as the best hand-constructed algorithms.
However, they can also be difficult to understand and reason about.
In particular, some genetic behaviors work very well when paired with certain
global behaviors, but experience catastrophic failures when paired with others.

The main contributions of this work are:
\begin{itemize}
    \item An investigation of two new low-density flocking settings, where
    flock formation is more difficult.
    \item The introduction of new placement strategies and influencing agent
    behaviors to adapt to the difficulties presented by these new settings.
    \item Analysis of the major differences in influencing agent priorities in
    low-density vs. high-density settings.
    \item A functional language to define ad hoc influencing agent behaviors.
    \item An evolutionary algorithm to evolve and evaluate candidate programs in
    this language.
    \item Analysis of the efficacy of the programs evolved by this algorithm and
    their strengths and shortcomings relative to hand-constructed algorithms.
\end{itemize}

The rest of this thesis is organized as follows: \S\ref{ch:background}
introduces background and related work.
\S\ref{ch:problem} describes the formal flocking model and the capabilities of
influencing agents, as well as the settings we wish to study.
\S\ref{ch:influencing} discusses the placement strategies and behaviors that we
study, as well as our strategy for evolving components of influencing agent
behavior.
In \S\ref{ch:evaluation}, we present our metrics and experimental frameworks,
followed by the results from our experiments.
Finally, we conclude and discuss future work in \S\ref{ch:conclusion}.

%\section{Radhika Intro}
%
%Across nature, flocking behavior can be found in a variety of species, from 
%flocks of birds, to herds of quadrupeds, schools of fish, or swarms of insects.
%In such species, groups exhibit collective behavior that emerges from simple, 
%local rules \cite{sumpter2010collective}.
%An open question is whether externally-controlled influencing agents can be 
%used to affect the behavior of flocks.
%For example, environmental engineers might want to steer flocks of birds away 
%from windmills, or steer a school of fish away from critical dam
%infrastructure.
%
%Previous work in the literature has primarily studied hand constructed
%behaviors for such influencing agents.
%In this work, we aim to explore a wider range of the solution space using
%evolutionary algorithms to automatically generate and evaluate different
%influencing behaviors.
%
%To start, we limit ourselves to purely ad hoc behaviors; influencing agents
%know of a goal direction ahead of time, but otherwise cannot co-ordinate with
%each other in any way.
%Instead, influencing agents must choose a direction simply based on the relative
%position and heading of their neighbors.
%This allows for direct comparisons to previous work by Genter and Stone, which
%proposed algorithms that operate under similar constraints
%\cite{genter2013backsearch, genter2013visionstationary,
%genter2014neighborsorientherd, genter2015placement,
%genter2016facegoalfacecurrent, genter201612steplookahead, genterthesis}.
%
%In order to build behaviors that work with variable numbers of neighbors, we
%evolve programs that are applied iteratively to each neighbor using
%a functional programming construct called a fold.
%In a fold, a function is applied in turn to each item in a list, updating an
%accumulator value for each one.
%The final value of the computation is the value of the accumulator after each
%item has been folded over.
%
%In our work, we define a simple language that performs arithmetic computations
%on scalar values and angles, and evolve different functions to use in the fold.
%To make the evolutionary process fast enough, we first evaluate different
%functions in a small environment, with six neighbors that start in a circle
%around a single influencing agent.
%We run four trials; in each trial, the six neighbors (and the influencing agent)
%are facing one of the cardinal directions, and the target direction is east.
%We measure the average angle offset from the goal direction of the flocking
%agents after $100$ steps and take the average across the four trials as the
%fitness value for the proposed program.
%We then run the evolutionary algorithm on this fitness value and mutate the
%best candidates each generation.
%
%Next, we evaluate the candidates generated by the evolutionary algorithm against
%a larger setting drawn from the literature.
%To help organize this part of the analysis, we split influencing agent design
%into three different aspects: placement strategy, local behaviors, and global
%behaviors.
%Placement strategies refer to the initial placement of influencing agents in
%the simulation space and their placement relative to flocking agents.
%Local behaviors dictate how an influencing agent attempts to influence local
%neighbors to face a given goal direction.
%These are equivalent to the ad hoc behaviors that we are evolving, and we use
%our evolved ad hoc behaviors for this aspect of the broader analysis.
%Global behaviors, on the other hand, dictate how influencing agents determine
%their goal direction.
%For example, we might program all the influencing agents to have a
%pre-determined goal direction such as East or South, or we might program a
%global behavior that picks a goal direction after some time based on the
%initial dynamics of the simulation.
%
%We take placement strategies and global behaviors from previous literature and
%evaluate their efficacy in a larger test setting, also drawn from the
%literature.
%In this setting, proposed in previous work \cite{Fu2017}, the agents start out
%in a $1000x1000$ toroidal grid, and the simulation is run until half the agents
%converge to one direction.
%In this setting, agent density is low, so interactions are rare.
%However, flock formation is still provably guaranteed, so the metric of interest
%is how much faster the influencing agents can help the Reynolds-Vicsek agents
%reach convergence.
%Previous work found that in low-density settings, it is important for agents to
%maintain influence over time; behaviors designed to quickly encourage
%convergence tended to turn influencing agents in directions that took them away
%from the flock.
%
%We find that the genetic behaviors can both encourage faster convergence in the
%short term while still maintaining influence over the long-term.
%As a result, they can outperform the best hand-constructed algorithms in small
%simulation spaces while not falling to the common pitfalls of the larger
%simulation spaces.
%However, they can also be difficult to understand and reason about.
%In particular, some genetic behaviors work very well when paired with certain
%global behaviors, but experience catastrophic failures when paired with other
%global behaviors.
%
%The main contributions of this work are:
%\begin{itemize}
%    \item A functional language to define ad hoc influencing agent behaviors.
%    \item An evolutionary algorithm to evolve and evaluate candidate programs in
%    this language.
%    \item Analysis of the efficacy of the programs evolved by this algorithm and
%    their strengths and shortcomings relative to hand-constructed algorithms.
%\end{itemize}
%
%The rest of this paper is organized as follows: \S\ref{sec:related} discusses
%recent work in this area and how it relates to our work.
%\S\ref{sec:problem} describes the formal flocking model and the role of
%influencing agents.
%\S\ref{sec:evolving} discusses our domain-specific language and evolutionary
%algorithm.
%\S\ref{sec:evaluation} describes our experimental setup in more detail, and
%presents the results of our experiments.
%Finally, we conclude and discuss future work in \S\ref{sec:conclusion}.

