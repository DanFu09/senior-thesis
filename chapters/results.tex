%!TEX root = ../dissertation.tex
\begin{savequote}[75mm]
Nulla facilisi. In vel sem. Morbi id urna in diam dignissim feugiat. Proin molestie tortor eu velit. Aliquam erat volutpat. Nullam ultrices, diam tempus vulputate egestas, eros pede varius leo.
\qauthor{Quoteauthor Lastname}
\end{savequote}

\chapter{Results}
\label{ch:results}

\section{Barbara Results}
\subsection{No Influencing Agents}
First, we briefly characterize the flocking behavior of a group of Reynolds-Viscek
agents without influencing agents in the \textit{large} and \textit{herd} settings.
We measure the number of clusters of agents that are path-connected and facing the
same direction; each of these clusters forms a small flock.
We also measure the number of lone agents (the number of agents with no neighbors).
Figure $\ref{fig:no_adhoc}$ shows graphs of these values over time for our two
settings.
\begin{figure}
    \centering
    \includegraphics[height=0.49\textwidth]{largeflockNoLegend}
    \includegraphics[height=0.49\textwidth]{largeloneNoLegend}
    \includegraphics[height=0.49\textwidth]{herdflockNoLegend}
    \includegraphics[height=0.49\textwidth]{herdloneWithLegend}
   % \begin{subfigure}[b]{0.24\textwidth}
   %     \includegraphics[width=\textwidth]{largeflockNoLegend}
   %     \label{fig:largeflock}
   % \end{subfigure}
   % \begin{subfigure}[b]{0.24\textwidth}
   %     \includegraphics[width=\textwidth]{largeloneNoLegend}
   %     \label{fig:largelone}
   % \end{subfigure}
   % \begin{subfigure}[b]{0.24\textwidth}
   %     \includegraphics[width=\textwidth]{herdflockNoLegend}
   %     \label{fig:largeflock}
   % \end{subfigure}
   % \begin{subfigure}[b]{0.24\textwidth}
   %     \includegraphics[width=\textwidth]{herdloneWithLegend}
   %     \label{fig:largelone}
   % \end{subfigure}
    \caption{Average flock counts and lone agent counts over time for the
    \textit{large} and \textit{herd} settings with no influencing agents,
    varying the number of Reynolds-Viscek agents.}
    \label{fig:no_adhoc}
\end{figure}

In the \textit{large} setting, there are two qualitative stages of convergence:
initial flock formation and flock unification.
In the first stage, individual agents collide with each other and form small
flocks.
In the second stage, these small flocks that formed collide with one another and
join together to form larger flocks.
In Figure $\ref{fig:no_adhoc}$, the first stage is represented by the initial
increase in the average number of flocks, and the second stage is represented
by the following decrease in the average number of flocks.
This behavior is reflected in the continually decreasing number of lone agents;
since the number of lone agents continues to decrease over time, we know that the
decrease in the total number of flocks is due to flock convergence.
Note that when there are more total agents, the absolute number of lone agents
decreases faster and reaches a similar value to the other cases by the end of the
simulation.
In other words, the \textit{ratio} of lone agents to total agents hits a
lower value when there are more agents, but the final absolute number of total
lone agents is still similar to the other cases.

The two stages of convergence also occur somewhat in the \textit{herd} setting,
but the second stage is cut off by the non-toroidal nature of the setup.
As flocks leave the starting area, the chances of interacting with other flocks
vastly decreases, so most of the flocks formed from the first stage never end up
merging with other flocks.
This is reflected in the plateaus of both the total number of flocks and the total
number of lone agents.
Some small artifacts in the graphs are worth mentioning; since the agents start off
in a much smaller area than in the \textit{large} setting, many of the agents
start out with a non-zero number of neighbors.
This causes the initial value of the average number of flocks to be non-zero, and
the average number of lone agents to be less than the total number of agents.

\subsection{Influencing Agents in the Large Setting}
Next, we study the efficacy of various behaviors and placement strategies in
the \textit{large} setting.
The average times for $50\%$ convergence under different combinations of placement
strategies with global and local behaviors are shown in Figure $\ref{fig:large}$.
We show graphs for $50$ influencing agents only, since the trends for the other
numbers of influencing agents were similar (the major difference being that
when there are more influencing agents, convergence happens faster).
Note that smaller is better in these graphs.
\begin{figure}
    \includegraphics[width=\textwidth]{large}
    \caption{Average times to 50\% convergence for $300$ Reynolds-Viscek agents
    with $50$ influencing agents in the \textit{large} setting under different
    placement strategies, paired with various global and local behaviors.
    Smaller is better.}
    \label{fig:large}
\end{figure}
The most immediately striking finding is that, in our more adverse setting,
the \textit{one step lookahead} and \textit{coordinated} local behaviors
significantly underperform the \textit{face} behavior irrespective of global
behavior and also underperform \textit{offset momentum} for the \textit{face}
and \textit{random} global behaviors.
This is an opposite result from Genter and Stone's findings on smaller simulation
spaces \cite{genter201612steplookahead, genterthesis}, which found that
\textit{one step lookahead} and \textit{coordinated} outperform \textit{face}
and \textit{offset momentum} (the latter of which are in fact presented as
``baseline" behaviors).
This finding is also rather counterintuitive; why should the ``smarter" behaviors
underperform the simpler behaviors?

The answer is that, when agent interactions are rare, it is more important for
influencing agents to \textit{maintain influence} than it is for them to quickly
change the direction of neighboring Reynolds-Viscek agents.
The \textit{one step lookahead} and \textit{coordinated} behaviors underperform
here because they tend to send influencing agents away from neighboring agents.
\begin{figure}
    \includegraphics[width=\textwidth]{losing_influence}
    \caption{An example of an influencing agent losing influence under the
    \textit{one step lookahead} behavior.
    The influencing agent is shown in red, and the Reynolds-Viscek agents are
    shown in white.
    In A, the influencing agent first encounters the flock of Reynolds-Viscek
    agents.
    In B-D, the influencing agent takes on directions that are oriented away
    from the goal direction to try to rapidly influence the Reynolds-Viscek
    agents.
    This changes the orientation of the Reynolds-Viscek agents, but the
    influencing agent has started to travel away from the flock by D.}
    \label{fig:losing_influence}
\end{figure}
An example of this phenomenon is shown in Figure $\ref{fig:losing_influence}$.
The influencing agent, shown in black, adopts an orientation that turns
neighboring Reynolds-Viscek agents towards the goal direction.
Even though this does turn Reynolds-Viscek agents towards the goal direction, it cannot
successfully turn all the agents in a single step; as a result, it must maintain
that orientation for future steps.
However, as long as the neighboring agents are not facing the goal direction,
the influencing agent's chosen orientation takes it away from the center of the
flock of Reynolds-Viscek agents, causing it to lose influence.
Once the influencing agent has lost influence, it is difficult to catch up to the
same flock, since influencing agents travel at the same speed\footnote{
There are some approaches which remove this speed constraint from
influencing agents \cite{han2010teleporting}.
However, this allows for unrealistic behaviors wherein influencing agents travel
to one Reynolds-Viscek agent and a time and change the direction of the
individual Reynolds-Viscek agent before moving on to the next one.
This results in Reynolds-Viscek agents that are all facing the same direction,
but that are often not path-connected.}
as Reynolds-Viscek agents.
As a result, the influencing agent is not actively influencing the direction of
any Reynolds-Viscek agents until it encounters another group of Reynolds-Viscek
agents.

Note that this effect also happens on a smaller simulation space, but it is
not nearly as pronounced; when interactions are very frequent, influencing
agents that have lost influence can find another group of Reynolds-Viscek
agents very quickly.
As a result, the gains from the smarter local algorithm still outweigh the
negative effects from losing influence.

This effect is more pronounced for the \textit{multistep} behaviors.
First, we note that the \textit{multistep} global behavior paired with the
\textit{face} local behavior seems to slightly outperform the \textit{direct}
and \textit{random} global behaviors, but the \textit{multistep} global behavior
paired with the other local behaviors drastically underperform anything else.
What is the root cause of this difference?
The \textit{multistep} global behavior starts out by creating many local flocks,
some of which have influencing agents in them.
When interactions are rare, the \textit{offset momentum}, \textit{one step
lookahead}, and \textit{coordinated} behaviors have difficulties changing the
orientation of existing flocks quickly before losing influence.
As a result, the \textit{multistep} behavior takes an order of magnitude longer
to reach convergence when paired with the other local behaviors.

Finally, we note that the effect of placement behaviors on convergence time
are almost non-existent.
When the density is lower, there is a much smaller chance that any influencing
agent will start out with more than one Reynolds-Viscek agent in its neighborhood,
even with the \textit{k-means} placement behavior.
As a result, even the best clustering approach is almost the same as starting
out randomly or in a grid.

\subsection{Influencing Agents in the Herd Setting}
Next, we evaluate results for our experiments in the \textit{herd} setting.
In many cases, measuring the number of agents facing the same direction is not
interesting here, since it is impossible to keep Reynolds-Viscek agents in one place
if they are facing the same direction.
Instead, we exclusively measure the number of Reynolds-Viscek agents that are
path-connected to influencing agents and facing the same direction as the influencing
agent.
This is a measure of ``control" of the Reynolds-Viscek agents.
The average number of agents in such local flocks after 15000 time steps is given
in Figure $\ref{fig:herd}$ for both the net and stationary behaviors.
\begin{figure}
    \centering
    \begin{subfigure}[b]{0.7\textwidth}
        \includegraphics[width=\textwidth]{herd_net}
    \end{subfigure}
    \begin{subfigure}[b]{0.7\textwidth}
        \includegraphics[width=\textwidth]{herd_stationary}
    \end{subfigure}
    \caption{Average number of agents under influencing agent control after $15000$
    steps with $300$ Reynolds-Viscek agents and $50$ influencing agents in the
    \textit{herd} setting under for various placement strategies
    and influencing agent behaviors.
    The net behavior moves the influencing agents and their Reynolds-Viscek agents
    off-screen, while the stationary behaviors keep the influencing agents near
    the goal area using some sort of circling technique.
    For the stationary behaviors, we found the only effective local behavior
    was \textit{face}, so it is the only local behavior displayed.
    Larger is better.}
    \label{fig:herd}
\end{figure}
% \begin{figure}
%     \centering
%     \includegraphics[width=0.50\textwidth]{herd_stationary}
%     \caption{Average number of agents under influencing agent control after $15,000$
%     steps with $300$ Reynolds-Viscek agents and $50$ influencing agents in the
%     \textit{herd} setting under various stationary behaviors and placement strategies.
%     Stationary behaviors keep the influencing agents near the goal area using some
%     sort of circling technique.
%     For these experiments, we found the only effective local behavior was \textit{face};
%     all the other local behaviors failed to keep Reynolds-Viscek agents under
%     influencing agent control after $15,000$ steps.
%     Larger is better.}
%     \label{fig:herd_stationary}
% \end{figure}
We find that the net behavior vastly outperforms any of the stationary
behaviors.
However, there may be environments in reality for which the net behavior is not
applicable (suppose it is strictly necessary to keep a flock in one place, for
instance).
Thus, we analyze the net behaviors separately from the stationary behaviors.

\subsubsection*{Net}
Again, we find that the \textit{face} local behavior tends to outperform the
\textit{offset momentum}, \textit{one step lookahead}, and \textit{coordinated}
local behaviors.
Again, we attribute this to the tendency of the \textit{offset momentum},
\textit{one step lookahead}, and \textit{coordinated} behaviors to lose
influence over time.
We note that the effect is not as pronounced here as in our \textit{large}
experiments, since each influencing agent has to control fewer agents.

In contrast to the \textit{large} experiments, we do find that the placement
strategy has a major effect on the efficacy of the net behavior.
Again, this has to do with density of influencing agents.
For example, notice that \textit{Border 750} (place the influencing agents in a
circle about the origin with radius $750$) vastly underperforms the other
placement strategies.
The larger radius results in a lower density of influencing agents, so a greater
number of Reynolds-Viscek agents slip through the ``holes" in the net.
Furthermore, by the time the Reynolds-Viscek agents reach the border, they have already
formed local flocks, and it is more difficult for the influencing agents to
point them in the right direction.
This effect is less pronounced for \textit{Random 750} and \textit{Grid 750},
since these strategies place influencing agents within the circle, and not simply
along its circumference.
As a result, the Reynolds-Viscek agents still encounter influencing agents before
reaching the circumference of the circle.

Finally, we note that \textit{k-means} outperforms all other placement strategies
by a few agents.
Again, the main driving factor behind this is agent density.
When an influencing agent starts out in a clustered area, it has at least one
other Reynolds-Viscek agent in its neighborhood.
As a result, its effective area of influence is slightly larger than with the
other placement strategies.
This helps it pick up more Reynolds-Viscek agents in the net.

\subsubsection*{Stationary}
For the stationary behaviors, we found that any local behavior except for
\textit{face} was almost completely ineffective; the average number of agents
under influencing agent control after $15000$ steps across $100$ trials was
almost $0$.
Again, this is a result of the inability of the \textit{offset momentum},
\textit{one step lookahead}, and \textit{coordinated} local behaviors to
maintain influence over time.
Each of the stationary behaviors requires the influencing agents to keep the
Reynolds-Viscek agents rotating about the origin in some way.
Without consistent influence, this is impossible.

Beyond that, we find that the \textit{multicircle} behavior slightly
underperforms the \textit{circle} behavior when paired with the
\textit{Border} placement strategies, but slightly overperforms when paired
with the  \textit{k-means}, \textit{Random}, \textit{Circle}, and
\textit{Grid} placement strategies, and performs the same as \textit{circle}
n the \textit{Grid} strategies.
What drives these trends?
Once \textit{multicircle} reaches the final stage, it is tracing a larger
circle than the \textit{circle} behavior traces on its own.
As a result, it is easier to maintain influence and turn the Reynolds-Viscek agents
over time in the final stage.
Before that, however, the influencing agents are in a following stage.
When the influencing agents start out inside the circle, they have more time to
infiltrate small flocks of Reynolds-Viscek agents and induce a circling behavior in
the final stage.

Finally, we note that \textit{Border 750} is the worst placement strategy,
for reasons similar to the reasons for the net behaviors, and \textit{polygon}
tends to underperform or match the performance of \textit{circle}.
This tells us that adopting occasional sharper turns can sometimes be harmful,
but not always.

\section{Radhika Results}
\subsection{Evolutionary Experiments}
We ran a total of $5$ evolutionary runs.
The first four had population size $25$ and ran for $50$ generations, while the
last one had population size $100$ and ran for $300$ generations.
For the first four runs, we selected the top $10$ genomes to seed the next
generation.
For the last run, we selected the top $20$ genomes.
As an optimization, we memoized genomes from generation to generation and re-used
results where possible.
We allowed for duplicate members in the population.
The average angle difference across the population and the angle difference of the
best genome in each generation are shown in Figure $\ref{fig:genetic_runs}$.
\begin{figure}
    \centering
    \includegraphics[width=0.45\textwidth]{run07}
    \includegraphics[width=0.45\textwidth]{run08}
    \includegraphics[width=0.45\textwidth]{run09}
    \includegraphics[width=0.45\textwidth]{run10}
    \includegraphics[width=0.45\textwidth]{run11}
    \caption{Average population fitness and fitness of the best candidate in the
    population over generations for a five different runs of the genetic algorithm.
    The first four runs had population size $25$ and ran for $50$ generations,
    while the last run has population size $100$ and ran for $300$ generations.
    Fitnesses of \textit{face}, \textit{offset momentum}, and \textit{one step
    lookahead} provided for comparison.}
    \label{fig:genetic_runs}
\end{figure}

In each run, the population converged to one or two best genomes that remained
in the seed population for every generation.
These best genomes consistently outperformed the hand-constructed local behaviors
taken from the literature.
However, the average angle difference across the population stayed relatively
high throughout the entire simulation, since the majority of the population
were the results of random mutation or crossover from the seed population.
In many cases, the new children perform very poorly, driving the average angle
difference up.
In the last run, with a population of size $100$, there is a sharp drop in the
average angle difference around generation $160$.
At this point in the evolutionary run, a single genome out-competed all the
others.
As a result, all subsequent populations were seeded by multiple copies of a
single genome, and mutations/crossover performed on this seed population
were relatively stable.

From these five evolutionary runs, we selected $7$ for further analysis.
These are shown in Table $\ref{table:genomes}$
\begin{table}[h]
\centering
\begin{tabular}{|c|c|}
    \hline
    \textbf{Name} & \textbf{Genome} \\
    \hline
    G1 & acc=goal; (mul acc (gez (cos heading) (exp (sin heading) distance) (sin goal))) \\ \hline
    G2 & acc=goal; (mul influence (mul influence goal)) \\ \hline
    G3 & acc=goal; (sub acc (mul -0.2678771899171444 goal)) \\ \hline
    G4 & acc=goal; (mul (mul acc (cos heading)) distance) \\ \hline
    \multirow{2}{*}{G5} & acc=goal; (mul distance (mul (sub (sub goal 0.2801770623593902) heading) \\
    & (mul (sub acc heading) goal))) \\ \hline
    \multirow{2}{*}{G6} & acc=goal; (mul distance (mul (sin influence) (mul (sub (sub goal 0.2801770623593902) heading) \\
    & (mul (sub (sub goal 0.2801770623593902) heading) goal)))) \\ \hline
    G7 & acc=goal; (mul goal (gez (cos acc) 0.19745673470999736 goal)) \\ \hline
\end{tabular}
\caption{Genomes from evolution}
\label{table:genomes}
\end{table}
These genomes bear a few similarities to each other; they all initialize the
accumulator to the goal direction, for example.
Beyond that, they share very little in common.
Some genomes (G1, G3, G5, G7) use the accumulator, while the others do not; some
are short and easy to parse (G2 is equivalent to $\frac{goal}{N^2}$, where
$N$ is the number of neighbors), while others are much more complicated.

Although they may be very different in expression, they are very similar to each
other in execution.
When all the agents are already facing east, these behaviors all have the
influencing agent face east as well.
In addition, they pick up some gains from the north and south starting conditions
by initially picking up more neighbors than the baseline conditions.
They pick up some major gains in the west case, where they intersect a few of
the neighbors to their east side and lead them towards the target direction
over the course of the next $100$ steps.
A few screenshots of this process are shown in Figure $\ref{fig:g1}$.
\begin{figure}
    \centering
    \includegraphics[width=0.32\textwidth]{westgenetic01}
    \includegraphics[width=0.32\textwidth]{westgenetic02}
    \includegraphics[width=0.32\textwidth]{westgenetic03}
    \caption{Screenshots of the G1 local behavior when trying to turn $6$
    Reynolds-Viscek agents $180$ degrees to the east.
    Instead of trying to turn all $6$ neighbors at once, as the \textit{one step
    lookahead} behavior does, the genetic behavior ``gives up" on some neighbors
    and just tries to turn the neighbors that are behind it.}
    \label{fig:g1}
\end{figure}
The other genetic processes behave very similarly to the behavior shown in the
screenshots, with slight variations (i.e., turning north instead of south, etc).

This behavior is very interesting scientifically for the differences between it
and \textit{one step lookahead}.
In particular, the genetic behaviors immediately turn towards the Reynolds-Viscek
agents behind them, and ignore the agents in front of them.
There are two major insights we can glean from this behavior.
First, when the influencing agents focus on the agents behind them, they can
successfully maintain influence over time instead of flying away from the flock
as they try to turn their neighbors towards the goal direction.
In other words, the genetic behaviors implicitly value influence over rapid
convergence.
We hypothesize that this arises because evaluation happens after $100$ steps and
not after $1$ step, as with \textit{one step lookahead}, but more work is
needed to answer this definitively.

Second, the influencing agents ignore the Reynolds-Viscek agents in front of
them.
There are a few reasons why this is beneficial.
Since the influencing agents have limited speed, they can never ``catch
up" to the agents directly in front of them.
The \textit{one step lookahead} algorithm does not take this into account;
as long as a neighbor is in range, its heading is factored into the calculation,
no matter whether the influencing agent can ever reach the neighbor.
Furthermore, it is much easier to lose influence over forward neighbors, since
any change in direction necessarily means that the influencing agent falls
behind.
Thus, the Reynolds-Viscek agents in front are somewhat of a lost cause, and it
is beneficial to ignore them.

\subsection{Influencing Agents in the Large Setting}
Next, we verify that the genetic algorithms are still effective when used in
larger settings and in conjunction with global behaviors and placement
strategies.
For example, \textit{one step lookahead} outperforms \textit{face} in the
small-scale evaluations we use during evolution, but underperforms \textit{face}
in simulations in the \textit{large} setting.
To remind the reader, the \textit{large} setting places Reynolds-Viscek agents
randomly on a toroidal $1000x1000$ grid with random initial orientations.
We evaluate our genetic behaviors paired with three placement strategies
(\textit{random}, \textit{grid}, and \textit{k-means}), and three global
behaviors (\textit{direct}, \textit{random}, and \textit{multistep}).
We place $300$ Reynolds-Viscek agents on the simulation space and use $50$
influencing agents.
We measure the number of steps necessary to reach $50\%$ convergence ($150$
Reynolds-Viscek agents all facing the same direction), measuring metrics every
$100$ time steps and averaging over $100$ trials.
The results are shown in Figure $\ref{fig:largegenetic}$.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{largegenetic}
    \caption{Average times to 50\% convergence for $300$ Reynolds-Viscek agents
    with $50$ influencing agents in the \textit{large} setting under different
    placement strategies, paired with various global and local behaviors.
    The \textit{Random} global behavior paired with the \textit{G5} local behavior
    performs very poorly; average convergence times are upwards of $30000$.
    Smaller is better.}
    \label{fig:largegenetic}
\end{figure}
We find that the efficacy of the genetic behaviors varies depending
on the global behavior.
In particular, the genetic behaviors all perform on par with, or slightly
better than, the \textit{face} local behavior when paired with the \textit{direct}
global behavior.
They all strongly outperform the \textit{one step lookahead} local behavior and
slightly outperform the \textit{offset momentum} local behavior.

When paired with the \textit{random} global behavior, however, the story changes
drastically.
Genetic behaviors G1, G4, and G7 still perform on par with the \textit{face} local
behavior, but G2, G3, and G6 start performing as poorly as \textit{one step
lookahead}.
G5 takes a major hit; instead of converging within $4000$ timesteps, it takes up to
$30000$ timesteps to converge.
From watching the simulations, a very peculiar behavior emerges: when the
influencing agent is moving in a random direction and meets a flock moving in a
similar direction, the agent continues moving in the direction of the flock
instead of turning the flock towards the goal direction.
It is not clear to us why this behavior emerges, especially since G5's genome
is one of the harder genomes to parse.

When paired with the \textit{multistep} global behavior, G1-3 once again
perform on par with the \textit{face} local behavior.
The G5 behavior again performs much worse, and the G6 behavior performs slightly
worse than the \textit{face} local behavior.
G4 and G7 perform slightly better than G1-3, and slightly outperform \textit{face}
(though not by a significant amount).
Notably, none of the genetic behaviors, not even G5, perform as badly as \textit{
offset momentum} and \textit{one step lookahead} do when paired with the
\textit{multistep} global behavior.
This is promising; it suggests that there are behaviors that can be more effective
than \textit{face} on a small scale but that can remain effective even when moving
to low-density settings.

% \subsection{Influencing Agents in the Herd Setting}
% BRIEFLY EXPLAIN THE HERD SETTING AND THE DIFFERENT COMBINATIONS AGAIN, THEN SHOW THE BIG GRAPH

% \begin{figure*}
%     \centering
%     \includegraphics[width=\textwidth]{herd_net_genetic}
%     \caption{Average number of agents under influencing agent control after $15000$
%     steps with $300$ Reynolds-Viscek agents and $50$ influencing agents in the
%     \textit{herd} setting under for various placement strategies
%     and local influencing agent behaviors, all paired with various global
%     \textit{net} behaviors.
%     Larger is better.}
%     \label{fig:herd_net}
% \end{figure*}

% To evaluate the contributions of influencing agents in the \textit{herd} setting
% we measure a slightly different metric.
% Since we have two qualitatively different categories of global behaviors (net
% behaviors vs. stationary behaviors), the number of agents facing the same
% direction is irrelevant, since the stationary behaviors rotate the agents around
% the origin (in fact, if the Reynolds-Viscek agents are all facing the same
% goal direction, the stationary behavior has failed).
% Instead, we measure the number of Reynolds-Viscek agents that are connected to
% influencing agents at $15000$ time steps; this is a measure of sustained
% influence over the Reynolds-Viscek agents over time.

% We examine three circular placement strategies, \textit{border}, \textit{random},
% and \textit{grid}, with two placement radii, \textit{500} and \textit{750}, along
% with the \textit{k-means} placement strategy.
% We split our examination of global behaviors between the \textit{net} behavior
% (analogous to \textit{face}) and three stationary behaviors - namely
% \textit{circle}, \textit{polygon}, and \textit{multicircle}.
% We use a polygon with ten sides (a decagon) for our \textit{polygon} experiments,
% and we vary the final radius for multicircle based on the initial placement
% radius.
% When the placement radius is \textit{500}, we set the final radius to
% \textit{900}; when the placement radius is \textit{750}, we set the final radius
% to \textit{1100}.
% Finally, we pair the \textit{face}, \textit{offset momentum}, \textit{one step
% lookahead}, and \textit{coordinated} local behaviors with all the global behaviors
% and placement strategies.
% We place $300$ Reynolds-Viscek agents inside a circle of radius $500$ at the center
% of a $5000x5000$ grid, varying the number of influencing agents from $10$ to $100$
% in intervals of $10$.
